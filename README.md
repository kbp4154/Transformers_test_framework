# Transformers Test Automation Framework

A modular, scalable **test automation framework** built to validate **Transformer** and **vLLM**-based pipelines at scale.  
Inspired by Hugging Faceâ€™s testing philosophy, this framework demonstrates how to run **100K+ distributed PyTest suites** across GPUs and CPUs with full CI/CD integration.

---

## Key Features

- âœ… **Scalable Test Architecture:** Parallel execution using `pytest-xdist` and dynamic fixtures.
- ðŸ§  **Cross-Version Compatibility:** Validate model behavior across `transformers` and `PyTorch` releases.
- ðŸ§© **CI/CD Integration:** Runs automatically via GitHub Actions on every push or pull request.
- ðŸ§° **Reproducibility Metrics:** Verifies consistent model outputs, tokenizer integrity, and inference latency.
- ðŸ“Š **Benchmark-Ready:** Extendable for large-scale regression, performance, and model evaluation workflows.

---

## Tech Stack

- **Languages:** Python 3.10+
- **Frameworks:** PyTest, Transformers, vLLM
- **Tools:** GitHub Actions, Docker (optional), `pytest-xdist`
- **Core Dependencies:**  
  ```bash
  pip install torch transformers pytest pytest-xdist
